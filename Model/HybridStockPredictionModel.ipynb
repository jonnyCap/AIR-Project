{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hybrid Stock Prediction Model\n",
    "\n",
    "This Model, specifically created to make Stock Predictions for upcoming Businesses, means this model predicts the market startup of any new business idea.\n",
    "\n",
    "### Model Architecture\n",
    "To create the most realistic approach possible, we created a hybrid model consisting of the following layers:\n",
    "1. Encodes business ideas using Sentence-BERT.\n",
    "2. Processes static company features using a dense layer.\n",
    "3. Combines both representations in a fusion layer.\n",
    "4. Uses an LSTM to make sequential predictions across a 12-month period.\n",
    "5. Outputs a prediction for each month in the forecast period.\n"
   ],
   "id": "5bfd1cf4c21a9cf9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T16:40:33.640903Z",
     "start_time": "2024-11-22T16:40:33.633813Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class StockPerformancePredictionModel(nn.Module):\n",
    "    def __init__(self, static_feature_dim, historical_dim, hidden_dim, forecast_steps):\n",
    "        super(StockPerformancePredictionModel, self).__init__()\n",
    "        \n",
    "        # Text representation layer (Sentence-BERT) \n",
    "        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        # Freeze Sentence-BERT parameters (optional)\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Static feature layer (for training only)\n",
    "        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n",
    "\n",
    "        # Historical stock data layer (for training only)\n",
    "        self.historical_fc = nn.Linear(historical_dim, hidden_dim)\n",
    "\n",
    "        # Fusion layer to combine all features (training) or text only (inference)\n",
    "        self.fusion_fc = nn.Linear(384 + 2 * hidden_dim, hidden_dim)  # 384 is the fixed text embedding dimension\n",
    "\n",
    "        # Fusion layer for inference (text-only input)\n",
    "        self.text_only_fc = nn.Linear(384, hidden_dim)  # 384 is the fixed text embedding dimension\n",
    "\n",
    "        # Time-series prediction (LSTM)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.output_fc = nn.Linear(hidden_dim, 1)  # Output single value per timestep\n",
    "\n",
    "        self.forecast_steps = forecast_steps\n",
    "\n",
    "    def forward(self, idea, static_features=None, historical_data=None, use_auxiliary_inputs=True, predict_autoregressively=False):\n",
    "        # Ensure device compatibility\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # Text embedding\n",
    "        encoded_output = self.text_encoder.encode(idea, convert_to_numpy=True)\n",
    "        print(type(encoded_output))  # Check if it's a NumPy array\n",
    "        text_embedding = torch.from_numpy(encoded_output).float().to(device)\n",
    "\n",
    "        print(f\"Text embedding: {text_embedding}\")\n",
    "        print(\"Encoded output contains NaN:\", np.isnan(encoded_output).any())\n",
    "        print(\"Encoded output contains Inf:\", np.isinf(encoded_output).any())\n",
    "\n",
    "\n",
    "# Add batch dimension if processing a single input\n",
    "        if text_embedding.dim() == 1:\n",
    "            text_embedding = text_embedding.unsqueeze(0)\n",
    "\n",
    "        # Use historical data and static features during training or when explicitly specified\n",
    "        if use_auxiliary_inputs:\n",
    "            # Static feature embedding\n",
    "            static_embedding = torch.relu(self.static_fc(static_features.to(device)))\n",
    "\n",
    "            # Historical stock data embedding\n",
    "            historical_embedding = torch.relu(self.historical_fc(historical_data.to(device)))\n",
    "\n",
    "            # Fusion with text + static + historical embeddings\n",
    "            combined_input = torch.cat((text_embedding, static_embedding, historical_embedding), dim=-1)\n",
    "            combined_input = torch.relu(self.fusion_fc(combined_input))\n",
    "        else:\n",
    "            # Text-only input (for inference)\n",
    "            combined_input = torch.relu(self.text_only_fc(text_embedding))\n",
    "\n",
    "        print(f\"Combined input: {combined_input}\")\n",
    "\n",
    "        if not predict_autoregressively:\n",
    "            # Repeat for time-series prediction (current behavior)\n",
    "            lstm_input = combined_input.unsqueeze(1).repeat(1, self.forecast_steps, 1)\n",
    "            lstm_out, _ = self.lstm(lstm_input)\n",
    "            predictions = self.output_fc(lstm_out).squeeze(-1)  # Shape: (batch_size, forecast_steps)\n",
    "            return predictions\n",
    "\n",
    "        else:\n",
    "            # Autoregressive prediction\n",
    "            predictions = []  # Use a list to collect the predictions\n",
    "            hidden_state = None  # Initialize hidden state for LSTM\n",
    "            input_step = combined_input.unsqueeze(1)  # Start with initial input for the first timestep\n",
    "\n",
    "            for _ in range(self.forecast_steps):\n",
    "                # Pass through LSTM for one timestep\n",
    "                lstm_out, hidden_state = self.lstm(input_step, hidden_state)\n",
    "                current_prediction = self.output_fc(lstm_out.squeeze(1))  # Predict for the current timestep\n",
    "                predictions.append(current_prediction)  # Append the current prediction to the list\n",
    "\n",
    "                # Use only text embedding for subsequent steps\n",
    "                input_step = torch.relu(self.text_only_fc(text_embedding)).unsqueeze(1)\n",
    "\n",
    "            # Stack predictions to form the final output\n",
    "            predictions = torch.stack(predictions, dim=1)  # Shape: (batch_size, forecast_steps)\n",
    "            return predictions\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example usage\n",
    "Here is an example of how to use our newly created model:"
   ],
   "id": "ffb934d9de7941ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:40:35.823012Z",
     "start_time": "2024-11-22T16:40:33.686463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Initialize the model - HAVE TO BE ADAPTED TO DATASET (Values are likely correct)\n",
    "static_feature_dim_num = 4    # Number of static features\n",
    "historical_dim_num = 12       # Number of historical stock performance points\n",
    "hidden_dim_num = 128          # Hidden layer size\n",
    "forecast_steps_num = 12       # Predict next 12 months\n",
    "\n",
    "model = StockPerformancePredictionModel(\n",
    "    static_feature_dim=static_feature_dim_num,\n",
    "    historical_dim=historical_dim_num,\n",
    "    hidden_dim=hidden_dim_num,\n",
    "    forecast_steps=forecast_steps_num\n",
    ")\n",
    "\n",
    "# Example input data\n",
    "idea_text = [\"AI-powered e-commerce platform targeting luxury goods.\"]\n",
    "fake_static_features = torch.tensor([[1e9, 500000, 0.25, 10]])  # Example static features (batch size = 1)\n",
    "fake_historical_data = torch.tensor([[0.05, 0.08, 0.06, -0.02, 0.07, 0.03, -0.01, 0.04, 0.02, 0.01, -0.03, 0.05]])  # Example historical data\n",
    "\n",
    "# Move to the same device as the model\n",
    "current_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(current_device)\n",
    "fake_static_features = fake_static_features.to(current_device)\n",
    "fake_historical_data = fake_historical_data.to(current_device)\n"
   ],
   "id": "43396d2bee8576ad",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After setting up the model we can use it like this:",
   "id": "ff716ca228d3b513"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:40:35.881185Z",
     "start_time": "2024-11-22T16:40:35.831581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass with simultaneous prediction\n",
    "first_predictions = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=False  # Default mode\n",
    ")\n",
    "\n",
    "print(\"Simultaneous Predictions:\", first_predictions)\n",
    "\n",
    "\n",
    "# Forward pass with autoregressive prediction\n",
    "predictions_autoregressive = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=True  # Autoregressive mode\n",
    ")\n",
    "\n",
    "print(\"Autoregressive Predictions:\", predictions_autoregressive)\n",
    "\n",
    "# Forward pass with text-only input\n",
    "predictions_text_only = model(\n",
    "    idea=idea_text,\n",
    "    use_auxiliary_inputs=False,\n",
    "    predict_autoregressively=False  # Simultaneous mode with text-only\n",
    ")\n",
    "\n",
    "print(\"Text-Only Predictions:\", predictions_text_only)\n"
   ],
   "id": "caf2a15dac0aa916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simultaneous Predictions: tensor([[-0.2989, -0.3566, -0.3654, -0.3666, -0.3668, -0.3668, -0.3668, -0.3668,\n",
      "         -0.3668, -0.3668, -0.3668, -0.3668]], grad_fn=<SqueezeBackward1>)\n",
      "Autoregressive Predictions: tensor([[[-0.2989],\n",
      "         [-0.1090],\n",
      "         [-0.0842],\n",
      "         [-0.0701],\n",
      "         [-0.0647],\n",
      "         [-0.0626],\n",
      "         [-0.0617],\n",
      "         [-0.0611],\n",
      "         [-0.0607],\n",
      "         [-0.0603],\n",
      "         [-0.0600],\n",
      "         [-0.0598]]], grad_fn=<StackBackward0>)\n",
      "Text-Only Predictions: tensor([[-0.0716, -0.0652, -0.0620, -0.0605, -0.0597, -0.0594, -0.0593, -0.0592,\n",
      "         -0.0592, -0.0592, -0.0593, -0.0593]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simple Training Loop",
   "id": "67ab46e00ad78620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:40:38.222530Z",
     "start_time": "2024-11-22T16:40:35.897451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example data (replace with your actual dataset)\n",
    "idea_texts_test = [\"AI-powered e-commerce platform\", \"Blockchain for supply chain management\"]\n",
    "static_features_test = torch.tensor([[1e6, 0.2, 10, 50], [5e5, 0.1, 5, 25]])  # Shape: (batch_size, static_feature_dim)\n",
    "historical_data_test = torch.tensor([[0.05, 0.08, 0.07, 0.03, 0.04, 0.06, 0.08, 0.09, 0.07, 0.05, 0.02, 0.01],\n",
    "                                [0.10, 0.09, 0.08, 0.06, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.00, -0.01]])  # Shape: (batch_size, historical_dim)\n",
    "targets = torch.tensor([[0.06, 0.07, 0.08, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01],\n",
    "                        [0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01, 0.00, -0.01, -0.02]])  # Shape: (batch_size, forecast_steps)\n",
    "\n",
    "# Define model parameters\n",
    "static_feature_dim_test = 4\n",
    "historical_dim_test = 12\n",
    "hidden_dim_test = 128\n",
    "forecast_steps_test = 12\n",
    "\n",
    "# Initialize the model\n",
    "model = StockPerformancePredictionModel(\n",
    "    static_feature_dim=static_feature_dim_test,\n",
    "    historical_dim=historical_dim_test,\n",
    "    hidden_dim=hidden_dim_test,\n",
    "    forecast_steps=forecast_steps_test\n",
    ")\n",
    "\n",
    "# Move model and data to the same device\n",
    "test_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(test_device)\n",
    "static_features_test = static_features_test.to(test_device)\n",
    "historical_data_test = historical_data_test.to(test_device)\n",
    "targets = targets.to(test_device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    test_predictions = model(\n",
    "        idea=idea_texts_test,\n",
    "        static_features=static_features_test,\n",
    "        historical_data=historical_data_test,\n",
    "        use_auxiliary_inputs=True\n",
    "    )\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(test_predictions, targets)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ],
   "id": "3d3559d051a584c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0540\n",
      "Epoch [2/10], Loss: 0.0412\n",
      "Epoch [3/10], Loss: 0.0302\n",
      "Epoch [4/10], Loss: 0.0211\n",
      "Epoch [5/10], Loss: 0.0139\n",
      "Epoch [6/10], Loss: 0.0084\n",
      "Epoch [7/10], Loss: 0.0046\n",
      "Epoch [8/10], Loss: 0.0023\n",
      "Epoch [9/10], Loss: 0.0014\n",
      "Epoch [10/10], Loss: 0.0015\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now we can test again:",
   "id": "fa68b7168e2a712"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:40:40.711911Z",
     "start_time": "2024-11-22T16:40:40.654898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_predictions = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=False  # Default mode\n",
    ")\n",
    "\n",
    "print(\"Simultaneous Predictions:\", first_predictions)\n",
    "\n",
    "\n",
    "# Forward pass with autoregressive prediction\n",
    "predictions_autoregressive = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=True  # Autoregressive mode\n",
    ")\n",
    "\n",
    "print(\"Autoregressive Predictions:\", predictions_autoregressive)\n",
    "\n",
    "# Forward pass with text-only input\n",
    "predictions_text_only = model(\n",
    "    idea=idea_text,\n",
    "    use_auxiliary_inputs=False,\n",
    "    predict_autoregressively=False  # Simultaneous mode with text-only\n",
    ")\n",
    "\n",
    "print(\"Text-Only Predictions:\", predictions_text_only)"
   ],
   "id": "f483a15d1da1a36f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simultaneous Predictions: tensor([[0.0374, 0.0729, 0.0783, 0.0790, 0.0791, 0.0791, 0.0792, 0.0792, 0.0792,\n",
      "         0.0792, 0.0792, 0.0792]], grad_fn=<SqueezeBackward1>)\n",
      "Autoregressive Predictions: tensor([[[ 0.0374],\n",
      "         [ 0.0018],\n",
      "         [-0.0032],\n",
      "         [ 0.0035],\n",
      "         [ 0.0122],\n",
      "         [ 0.0192],\n",
      "         [ 0.0239],\n",
      "         [ 0.0268],\n",
      "         [ 0.0286],\n",
      "         [ 0.0295],\n",
      "         [ 0.0300],\n",
      "         [ 0.0303]]], grad_fn=<StackBackward0>)\n",
      "Text-Only Predictions: tensor([[0.0368, 0.0338, 0.0320, 0.0310, 0.0305, 0.0303, 0.0303, 0.0303, 0.0303,\n",
      "         0.0303, 0.0304, 0.0304]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
