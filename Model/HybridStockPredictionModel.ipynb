{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hybrid Stock Prediction Model\n",
    "\n",
    "This Model, specifically created to make Stock Predictions for upcoming Businesses, means this model predicts the market startup of any new business idea.\n",
    "\n",
    "### Model Architecture\n",
    "To create the most realistic approach possible, we created a hybrid model consisting of the following layers:\n",
    "1. Encodes business ideas using Sentence-BERT.\n",
    "2. Processes static company features using a dense layer.\n",
    "3. Combines both representations in a fusion layer.\n",
    "4. Uses an LSTM to make sequential predictions across a 12-month period.\n",
    "5. Outputs a prediction for each month in the forecast period.\n"
   ],
   "id": "5bfd1cf4c21a9cf9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-15T16:10:25.703440Z",
     "start_time": "2024-11-15T16:10:25.697065Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class StockPerformancePredictionModel(nn.Module):\n",
    "    def __init__(self, static_feature_dim, historical_dim, hidden_dim, forecast_steps):\n",
    "        super(StockPerformancePredictionModel, self).__init__()\n",
    "\n",
    "        # Text representation layer (Sentence-BERT)\n",
    "        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        # Freeze Sentence-BERT parameters (optional)\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Static feature layer (for training only)\n",
    "        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n",
    "\n",
    "        # Historical stock data layer (for training only)\n",
    "        self.historical_fc = nn.Linear(historical_dim, hidden_dim)\n",
    "\n",
    "        # Fusion layer to combine all features (training) or text only (inference)\n",
    "        self.fusion_fc = nn.Linear(384 + 2 * hidden_dim, hidden_dim)  # 384 is the fixed text embedding dimension\n",
    "\n",
    "        # Fusion layer for inference (text-only input)\n",
    "        self.text_only_fc = nn.Linear(384, hidden_dim)  # 384 is the fixed text embedding dimension\n",
    "\n",
    "        # Time-series prediction (LSTM)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.output_fc = nn.Linear(hidden_dim, 1)  # Output single value per timestep\n",
    "\n",
    "        self.forecast_steps = forecast_steps\n",
    "\n",
    "    def forward(self, idea, static_features=None, historical_data=None, use_auxiliary_inputs=True, predict_autoregressively=False):\n",
    "        # Ensure device compatibility\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # Text embedding\n",
    "        text_embedding = torch.tensor(\n",
    "            self.text_encoder.encode(idea, convert_to_numpy=True)\n",
    "        ).to(device)\n",
    "\n",
    "        # Add batch dimension if processing a single input\n",
    "        if text_embedding.dim() == 1:\n",
    "            text_embedding = text_embedding.unsqueeze(0)\n",
    "\n",
    "        # Use historical data and static features during training or when explicitly specified\n",
    "        if use_auxiliary_inputs:\n",
    "            # Static feature embedding\n",
    "            static_embedding = torch.relu(self.static_fc(static_features.to(device)))\n",
    "\n",
    "            # Historical stock data embedding\n",
    "            historical_embedding = torch.relu(self.historical_fc(historical_data.to(device)))\n",
    "\n",
    "            # Fusion with text + static + historical embeddings\n",
    "            combined_input = torch.cat((text_embedding, static_embedding, historical_embedding), dim=-1)\n",
    "            combined_input = torch.relu(self.fusion_fc(combined_input))\n",
    "        else:\n",
    "            # Text-only input (for inference)\n",
    "            combined_input = torch.relu(self.text_only_fc(text_embedding))\n",
    "\n",
    "        if not predict_autoregressively:\n",
    "            # Repeat for time-series prediction (current behavior)\n",
    "            lstm_input = combined_input.unsqueeze(1).repeat(1, self.forecast_steps, 1)\n",
    "            lstm_out, _ = self.lstm(lstm_input)\n",
    "            predictions = self.output_fc(lstm_out).squeeze(-1)  # Shape: (batch_size, forecast_steps)\n",
    "            return predictions\n",
    "\n",
    "        else:\n",
    "            # Autoregressive prediction\n",
    "            predictions = []  # Use a list to collect the predictions\n",
    "            hidden_state = None  # Initialize hidden state for LSTM\n",
    "            input_step = combined_input.unsqueeze(1)  # Start with initial input for the first timestep\n",
    "\n",
    "            for _ in range(self.forecast_steps):\n",
    "                # Pass through LSTM for one timestep\n",
    "                lstm_out, hidden_state = self.lstm(input_step, hidden_state)\n",
    "                current_prediction = self.output_fc(lstm_out.squeeze(1))  # Predict for the current timestep\n",
    "                predictions.append(current_prediction)  # Append the current prediction to the list\n",
    "\n",
    "                # Use only text embedding for subsequent steps\n",
    "                input_step = torch.relu(self.text_only_fc(text_embedding)).unsqueeze(1)\n",
    "\n",
    "            # Stack predictions to form the final output\n",
    "            predictions = torch.stack(predictions, dim=1)  # Shape: (batch_size, forecast_steps)\n",
    "            return predictions\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example usage\n",
    "Here is an example of how to use our newly created model:"
   ],
   "id": "ffb934d9de7941ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:10:37.500622Z",
     "start_time": "2024-11-15T16:10:25.712432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Initialize the model - HAVE TO BE ADAPTED TO DATASET (Values are likely correct)\n",
    "static_feature_dim_num = 4    # Number of static features\n",
    "historical_dim_num = 12       # Number of historical stock performance points\n",
    "hidden_dim_num = 128          # Hidden layer size\n",
    "forecast_steps_num = 12       # Predict next 12 months\n",
    "\n",
    "model = StockPerformancePredictionModel(\n",
    "    static_feature_dim=static_feature_dim_num,\n",
    "    historical_dim=historical_dim_num,\n",
    "    hidden_dim=hidden_dim_num,\n",
    "    forecast_steps=forecast_steps_num\n",
    ")\n",
    "\n",
    "# Example input data\n",
    "idea_text = [\"AI-powered e-commerce platform targeting luxury goods.\"]\n",
    "fake_static_features = torch.tensor([[1e9, 500000, 0.25, 10]])  # Example static features (batch size = 1)\n",
    "fake_historical_data = torch.tensor([[0.05, 0.08, 0.06, -0.02, 0.07, 0.03, -0.01, 0.04, 0.02, 0.01, -0.03, 0.05]])  # Example historical data\n",
    "\n",
    "# Move to the same device as the model\n",
    "current_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(current_device)\n",
    "fake_static_features = fake_static_features.to(current_device)\n",
    "fake_historical_data = fake_historical_data.to(current_device)\n"
   ],
   "id": "43396d2bee8576ad",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After setting up the model we can use it like this:",
   "id": "ff716ca228d3b513"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:10:37.547427Z",
     "start_time": "2024-11-15T16:10:37.511723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass with simultaneous prediction\n",
    "first_predictions = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=False  # Default mode\n",
    ")\n",
    "\n",
    "print(\"Simultaneous Predictions:\", first_predictions)\n",
    "\n",
    "\n",
    "# Forward pass with autoregressive prediction\n",
    "predictions_autoregressive = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=True  # Autoregressive mode\n",
    ")\n",
    "\n",
    "print(\"Autoregressive Predictions:\", predictions_autoregressive)\n",
    "\n",
    "# Forward pass with text-only input\n",
    "predictions_text_only = model(\n",
    "    idea=idea_text,\n",
    "    use_auxiliary_inputs=False,\n",
    "    predict_autoregressively=False  # Simultaneous mode with text-only\n",
    ")\n",
    "\n",
    "print(\"Text-Only Predictions:\", predictions_text_only)\n"
   ],
   "id": "caf2a15dac0aa916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simultaneous Predictions: tensor([[-0.1862, -0.2113, -0.2151, -0.2157, -0.2157, -0.2157, -0.2157, -0.2157,\n",
      "         -0.2157, -0.2157, -0.2157, -0.2157]], grad_fn=<SqueezeBackward1>)\n",
      "Autoregressive Predictions: tensor([[[-0.1862],\n",
      "         [-0.0966],\n",
      "         [-0.0671],\n",
      "         [-0.0557],\n",
      "         [-0.0538],\n",
      "         [-0.0554],\n",
      "         [-0.0575],\n",
      "         [-0.0593],\n",
      "         [-0.0606],\n",
      "         [-0.0614],\n",
      "         [-0.0620],\n",
      "         [-0.0624]]], grad_fn=<StackBackward0>)\n",
      "Text-Only Predictions: tensor([[-0.0511, -0.0567, -0.0598, -0.0614, -0.0623, -0.0627, -0.0628, -0.0629,\n",
      "         -0.0630, -0.0630, -0.0630, -0.0630]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simple Training Loop",
   "id": "67ab46e00ad78620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:10:39.734676Z",
     "start_time": "2024-11-15T16:10:37.566210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example data (replace with your actual dataset)\n",
    "idea_texts_test = [\"AI-powered e-commerce platform\", \"Blockchain for supply chain management\"]\n",
    "static_features_test = torch.tensor([[1e6, 0.2, 10, 50], [5e5, 0.1, 5, 25]])  # Shape: (batch_size, static_feature_dim)\n",
    "historical_data_test = torch.tensor([[0.05, 0.08, 0.07, 0.03, 0.04, 0.06, 0.08, 0.09, 0.07, 0.05, 0.02, 0.01],\n",
    "                                [0.10, 0.09, 0.08, 0.06, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.00, -0.01]])  # Shape: (batch_size, historical_dim)\n",
    "targets = torch.tensor([[0.06, 0.07, 0.08, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01],\n",
    "                        [0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01, 0.00, -0.01, -0.02]])  # Shape: (batch_size, forecast_steps)\n",
    "\n",
    "# Define model parameters\n",
    "static_feature_dim_test = 4\n",
    "historical_dim_test = 12\n",
    "hidden_dim_test = 128\n",
    "forecast_steps_test = 12\n",
    "\n",
    "# Initialize the model\n",
    "model = StockPerformancePredictionModel(\n",
    "    static_feature_dim=static_feature_dim_test,\n",
    "    historical_dim=historical_dim_test,\n",
    "    hidden_dim=hidden_dim_test,\n",
    "    forecast_steps=forecast_steps_test\n",
    ")\n",
    "\n",
    "# Move model and data to the same device\n",
    "test_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(test_device)\n",
    "static_features_test = static_features_test.to(test_device)\n",
    "historical_data_test = historical_data_test.to(test_device)\n",
    "targets = targets.to(test_device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    test_predictions = model(\n",
    "        idea=idea_texts_test,\n",
    "        static_features=static_features_test,\n",
    "        historical_data=historical_data_test,\n",
    "        use_auxiliary_inputs=True\n",
    "    )\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(test_predictions, targets)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ],
   "id": "3d3559d051a584c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0081\n",
      "Epoch [2/10], Loss: 0.0037\n",
      "Epoch [3/10], Loss: 0.0014\n",
      "Epoch [4/10], Loss: 0.0010\n",
      "Epoch [5/10], Loss: 0.0017\n",
      "Epoch [6/10], Loss: 0.0026\n",
      "Epoch [7/10], Loss: 0.0029\n",
      "Epoch [8/10], Loss: 0.0028\n",
      "Epoch [9/10], Loss: 0.0022\n",
      "Epoch [10/10], Loss: 0.0016\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now we can test again:",
   "id": "fa68b7168e2a712"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:10:39.779888Z",
     "start_time": "2024-11-15T16:10:39.745226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_predictions = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=False  # Default mode\n",
    ")\n",
    "\n",
    "print(\"Simultaneous Predictions:\", first_predictions)\n",
    "\n",
    "\n",
    "# Forward pass with autoregressive prediction\n",
    "predictions_autoregressive = model(\n",
    "    idea=idea_text,\n",
    "    static_features=fake_static_features,\n",
    "    historical_data=fake_historical_data,\n",
    "    use_auxiliary_inputs=True,\n",
    "    predict_autoregressively=True  # Autoregressive mode\n",
    ")\n",
    "\n",
    "print(\"Autoregressive Predictions:\", predictions_autoregressive)\n",
    "\n",
    "# Forward pass with text-only input\n",
    "predictions_text_only = model(\n",
    "    idea=idea_text,\n",
    "    use_auxiliary_inputs=False,\n",
    "    predict_autoregressively=False  # Simultaneous mode with text-only\n",
    ")\n",
    "\n",
    "print(\"Text-Only Predictions:\", predictions_text_only)"
   ],
   "id": "f483a15d1da1a36f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simultaneous Predictions: tensor([[0.0632, 0.0585, 0.0578, 0.0577, 0.0577, 0.0577, 0.0577, 0.0577, 0.0577,\n",
      "         0.0577, 0.0577, 0.0577]], grad_fn=<SqueezeBackward1>)\n",
      "Autoregressive Predictions: tensor([[[ 0.0632],\n",
      "         [-0.0543],\n",
      "         [-0.0549],\n",
      "         [-0.0624],\n",
      "         [-0.0679],\n",
      "         [-0.0695],\n",
      "         [-0.0689],\n",
      "         [-0.0675],\n",
      "         [-0.0660],\n",
      "         [-0.0647],\n",
      "         [-0.0638],\n",
      "         [-0.0631]]], grad_fn=<StackBackward0>)\n",
      "Text-Only Predictions: tensor([[-0.0568, -0.0590, -0.0604, -0.0612, -0.0616, -0.0618, -0.0618, -0.0619,\n",
      "         -0.0619, -0.0619, -0.0619, -0.0618]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 60
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
