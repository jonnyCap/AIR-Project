{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hybrid Stock Prediction Model\n",
    "\n",
    "This Model, specifically created to make Stock Predictions for upcoming Businesses, means this model predicts the market startup of any new business idea.\n",
    "\n",
    "### Model Architecture\n",
    "To create the most realistic approach possible, we created a hybrid model consisting of the following layers:\n",
    "1. Encodes business ideas using Sentence-BERT.\n",
    "2. Processes static company features using a dense layer.\n",
    "3. Combines both representations in a fusion layer.\n",
    "4. Uses an LSTM to make sequential predictions across a 12-month period.\n",
    "5. Outputs a prediction for each month in the forecast period.\n"
   ],
   "id": "5bfd1cf4c21a9cf9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:38:05.589621Z",
     "start_time": "2024-11-12T07:38:01.605405Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class StockPerformancePredictionModel(nn.Module):\n",
    "    def __init__(self, text_embedding_dim, static_feature_dim, hidden_dim, forecast_steps):\n",
    "        super(StockPerformancePredictionModel, self).__init__()\n",
    "\n",
    "        # Text representation layer (Sentence-BERT)\n",
    "        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        # Freeze Sentence-BERT parameters (optional, if you don't want fine-tuning)\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Static feature layer\n",
    "        self.static_fc = nn.Linear(static_feature_dim, hidden_dim)\n",
    "\n",
    "        # Fusion layer\n",
    "        self.fusion_fc = nn.Linear(text_embedding_dim + hidden_dim, hidden_dim)\n",
    "\n",
    "        # Time-series prediction (LSTM)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.output_fc = nn.Linear(hidden_dim, 1)  # Output single value per time step\n",
    "        self.forecast_steps = forecast_steps\n",
    "\n",
    "    def forward(self, idea_text, static_features):\n",
    "        # Ensure static_features is on the same device as the model\n",
    "        device = next(self.parameters()).device\n",
    "        static_features = static_features.to(device)\n",
    "\n",
    "        # Text embedding\n",
    "        text_embedding = torch.tensor(\n",
    "            self.text_encoder.encode(idea_text, convert_to_numpy=True)\n",
    "        ).to(device)\n",
    "\n",
    "        # Add batch dimension if processing a single input\n",
    "        if text_embedding.dim() == 1:\n",
    "            text_embedding = text_embedding.unsqueeze(0)\n",
    "\n",
    "        # Static feature embedding\n",
    "        static_embedding = torch.relu(self.static_fc(static_features))\n",
    "\n",
    "        # Fusion\n",
    "        combined_input = torch.cat((text_embedding, static_embedding), dim=-1)\n",
    "        combined_input = torch.relu(self.fusion_fc(combined_input))\n",
    "\n",
    "        # Repeat for time-series prediction\n",
    "        lstm_input = combined_input.unsqueeze(1).repeat(1, self.forecast_steps, 1)\n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "\n",
    "        # Generate monthly predictions\n",
    "        predictions = self.output_fc(lstm_out).squeeze(-1)  # Shape: (batch_size, forecast_steps)\n",
    "        return predictions\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example usage\n",
    "Here is an example of how to use our newly created model:"
   ],
   "id": "ffb934d9de7941ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:40:53.852069Z",
     "start_time": "2024-11-12T07:40:51.338801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate the model with appropriate dimensions\n",
    "model = StockPerformancePredictionModel(text_embedding_dim=384, static_feature_dim=10, hidden_dim=128, forecast_steps=12)\n",
    "\n",
    "# Define input data\n",
    "idea_text = \"Innovative AI-driven approach to personalized medicine.\"\n",
    "static_features = torch.randn(1, 10)  # Corrected static feature input for batch_size = 1\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model(idea_text, static_features)\n",
    "print(predictions.shape)  # Expected shape: (1, 12)\n",
    "\n"
   ],
   "id": "43396d2bee8576ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
