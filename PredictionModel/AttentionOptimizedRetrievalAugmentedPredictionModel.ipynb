{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Attention Optimized Retrieval Augmented Prediction Model\n",
    "\n",
    "This Model, specifically created to make Stock Predictions for upcoming Businesses, means this model predicts the market startup of any new business idea.\n"
   ],
   "id": "5bfd1cf4c21a9cf9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T11:30:52.774001Z",
     "start_time": "2025-01-10T11:30:52.759554Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "from RetrievalSystem.RetrievalSystem import RetrievalSystem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PredictionModel.Layers.AttentionOptimizedLayers import IdeaLayer, IdeaStaticLayer, IdeaHistoricalLayer, OutputLayer, FirstFusionLayer, SecondFusionLayer\n",
    "\n",
    "INPUT_PATH = \"../RetrievalSystem/Embeddings/embeddings.csv\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "BERT_DIM = 384\n",
    "\n",
    "class RetrievalAugmentedPredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 128, ret_sys: RetrievalSystem = None, static_dim = 34, historical_dim = 72, forecast_steps: int = 6, retrieval_number: int = 16):\n",
    "        super(RetrievalAugmentedPredictionModel, self).__init__()\n",
    "\n",
    "        if forecast_steps % 3 != 0:\n",
    "            raise ValueError(\"forecast_steps must be a multiple of 3\")\n",
    "\n",
    "        self.forecast_steps = forecast_steps\n",
    "        self.static_feature_dim = static_dim\n",
    "        self.historical_feature_dim = historical_dim\n",
    "        self.historical_idea_dim = forecast_steps\n",
    "        self.retrieval_number = retrieval_number\n",
    "\n",
    "        # Retrieval Model\n",
    "        if ret_sys:\n",
    "            self.retrieval_system = ret_sys\n",
    "        else:\n",
    "            self.retrieval_system = RetrievalSystem(INPUT_PATH, retrieval_number)\n",
    "\n",
    "        # Layers for new Idea\n",
    "        self.idea_fc = IdeaLayer(bert_dim=BERT_DIM, hidden_dim=hidden_dim)\n",
    "        self.idea_static_fc = IdeaStaticLayer(static_feature_dim=self.static_feature_dim)\n",
    "        self.idea_historical_fc = IdeaHistoricalLayer(historical_idea_dim=self.historical_idea_dim, hidden_dim=hidden_dim)\n",
    "\n",
    "        self.document_fusion_fc = FirstFusionLayer(input_dim=self.historical_feature_dim + self.static_feature_dim + BERT_DIM + 1, hidden_dim=hidden_dim)\n",
    "\n",
    "        self.idea_fusion_fc = SecondFusionLayer(hidden_dim=hidden_dim)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.pre_attention = nn.MultiheadAttention(embed_dim=2 * hidden_dim, num_heads=4, batch_first=True)\n",
    "\n",
    "        # Multi-layer LSTM with residual connection\n",
    "        self.lstm = nn.LSTM(input_size=2*hidden_dim, hidden_size=2*hidden_dim, num_layers=4, batch_first=True, dropout=0.2)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.post_attention = nn.MultiheadAttention(embed_dim=2 * hidden_dim, num_heads=2, batch_first=True)\n",
    "\n",
    "        # Output layer for forecasting\n",
    "        self.output_fc = OutputLayer(hidden_dim=2*hidden_dim, retrieval_number=self.retrieval_number)\n",
    "\n",
    "\n",
    "    def forward(self, ideas: list=None, retrieval_result=None, dataset: pd.DataFrame = None, static_features=None, historical_data=None, use_auxiliary_inputs=True, excluded_tickers: dict = None):\n",
    "        # Ensure device compatibility\n",
    "\n",
    "        if excluded_tickers is None:\n",
    "            excluded_tickers = {}\n",
    "\n",
    "        if dataset is None:\n",
    "            print(\"We need a dataset for retrieval\")\n",
    "            return None\n",
    "\n",
    "        if not ideas and not retrieval_result:\n",
    "            print(\"We need either an idea text or a retrieval result\")\n",
    "            return None\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # --- Retrieval Model ---\n",
    "        # Batch retrieve embeddings and documents\n",
    "        if not retrieval_result:\n",
    "            retrieval_result = self.retrieval_system.find_similar_entries_for_batch(texts=ideas, top_n=self.retrieval_number, excluded_tickers=excluded_tickers)\n",
    "\n",
    "        # Define static and month columns\n",
    "        static_columns = [\n",
    "            col for col in dataset.columns\n",
    "            if col not in [\"tickers\", \"business_description\", \"embedding\", \"similarity\"] and not col.startswith(\"month\")\n",
    "        ]\n",
    "        month_columns = [col for col in dataset.columns if col.startswith(\"month\")]\n",
    "\n",
    "        # Extract embeddings, similarities, and tickers for the batch\n",
    "        idea_embeddings, retrieved_embeddings, combined_data = [], [], []\n",
    "\n",
    "        for embedding, documents in retrieval_result:\n",
    "            idea_embeddings.append(embedding)\n",
    "\n",
    "            # Convert documents to a DataFrame if necessary\n",
    "            if isinstance(documents, list):\n",
    "                documents = pd.DataFrame(documents)\n",
    "\n",
    "            # Ensure `tickers` column has the same type in both DataFrames\n",
    "            documents['tickers'] = documents['tickers'].astype(str)\n",
    "            if dataset.index.name == 'tickers':\n",
    "                dataset = dataset.reset_index()\n",
    "            dataset['tickers'] = dataset['tickers'].astype(str)\n",
    "\n",
    "            # Join dataset on `tickers`\n",
    "            joined_data = documents.join(dataset.set_index('tickers'), on='tickers', how='left')\n",
    "\n",
    "            # Convert embedding and similarity columns to PyTorch tensors\n",
    "            embeddings_tensor = torch.stack(\n",
    "                [torch.tensor(e, dtype=torch.float32) for e in joined_data['embedding']],\n",
    "                dim=0\n",
    "            ).to(device)  # Shape: [num_documents, embedding_dim]\n",
    "\n",
    "            similarities_tensor = torch.stack(\n",
    "                [torch.tensor(s, dtype=torch.float32) for s in joined_data['similarity']],\n",
    "                dim=0\n",
    "            ).to(device)  # Shape: [num_documents, similarity_dim]\n",
    "\n",
    "            # Drop `embedding` and `similarity` columns\n",
    "            joined_data = joined_data.drop(columns=['embedding', 'similarity'])\n",
    "\n",
    "            # Select and process static and month columns\n",
    "            numeric_data = joined_data[static_columns + month_columns].apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "            numeric_tensor = torch.tensor(numeric_data, dtype=torch.float32).to(device)  # Shape: [num_documents, static_dim + month_dim]\n",
    "\n",
    "            # Concatenate tensors along feature dimension (dim=1)\n",
    "            print(\"Embeddings Tensor Shape:\", embeddings_tensor.shape)\n",
    "            print(\"Similarities Tensor Shape:\", similarities_tensor.shape)\n",
    "            print(\"Numeric Tensor Shape:\", numeric_tensor.shape)\n",
    "\n",
    "            combined_tensor = torch.cat((embeddings_tensor, similarities_tensor.unsqueeze(1), numeric_tensor), dim=1)  # Shape: [num_documents, total_feature_dim]\n",
    "            combined_data.append(combined_tensor)\n",
    "\n",
    "\n",
    "        # Convert to tensors for further processing\n",
    "        combined_tensor = torch.stack(combined_data, dim=0)  # Shape: [batch_size, sequence_length, feature_dim]\n",
    "\n",
    "        combined_output = self.document_fusion_fc(combined_tensor)\n",
    "\n",
    "        print(f\"Shape of combined_tensor: {combined_output.shape}\")\n",
    "\n",
    "        # Put new ideas data into input layers\n",
    "        idea_embeddings = torch.tensor(np.array(idea_embeddings, dtype=np.float32), dtype=torch.float32).to(device).squeeze(1)\n",
    "        idea_output = self.idea_fc(idea_embeddings)\n",
    "\n",
    "        batch_size = idea_embeddings.size(0)\n",
    "        if use_auxiliary_inputs:\n",
    "            static_tensor = static_features.clone().to(torch.float32).to(device)\n",
    "            historical_tensor = historical_data.clone().to(device)\n",
    "        else:\n",
    "            static_tensor = torch.zeros((batch_size, self.static_feature_dim), dtype=torch.float32).to(device)\n",
    "            historical_tensor = torch.zeros((batch_size, self.historical_idea_dim), dtype=torch.float32).to(device)\n",
    "\n",
    "        static_output = self.idea_static_fc(static_tensor) # This wont change within the autoregressiv prediction\n",
    "\n",
    "        # --- Autoregressive prediction ---\n",
    "        predictions = []\n",
    "        pre_attention_weights = []\n",
    "        post_attention_weights = []\n",
    "        lstm_hidden_states = []  # To store the second output (hidden states) of the LSTM\n",
    "\n",
    "        for step in range(self.forecast_steps // 3):  # Predict 3 steps at a time\n",
    "            historical_output = self.idea_historical_fc(historical_tensor)\n",
    "            combined_input = torch.cat((static_output, historical_output, idea_output), dim=1)\n",
    "            idea_tensor = self.idea_fusion_fc(combined_input).unsqueeze(1)\n",
    "\n",
    "            # Pre attention\n",
    "            combined_tensor_with_idea = torch.cat((combined_output, idea_tensor), dim=1)\n",
    "            lstm_attention_output, pre_weights = self.pre_attention(\n",
    "                combined_tensor_with_idea, combined_tensor_with_idea, combined_tensor_with_idea\n",
    "            )\n",
    "            pre_attention_weights.append(pre_weights)  # Store pre-attention weights\n",
    "\n",
    "            # LSTM\n",
    "            lstm_output, (h_n, c_n) = self.lstm(lstm_attention_output)  # Capture LSTM's second output\n",
    "            lstm_hidden_states.append((h_n, c_n))  # Store hidden and cell states\n",
    "\n",
    "            # Post attention\n",
    "            lstm_attention_output, post_weights = self.post_attention(lstm_output, lstm_output, lstm_output)\n",
    "            post_attention_weights.append(post_weights)  # Store post-attention weights\n",
    "\n",
    "            # Aggregate using mean pooling\n",
    "            aggregated_output = torch.mean(lstm_attention_output, dim=1)  # Shape: [batch_size, hidden_dim]\n",
    "\n",
    "            # OUTPUT\n",
    "            final_prediction = self.output_fc(aggregated_output)  # Now returns [batch_size, 3]\n",
    "\n",
    "            # Append to predictions\n",
    "            predictions.append(final_prediction)  # Shape: [batch_size, 3]\n",
    "\n",
    "            # Update historical tensor for next step\n",
    "            historical_tensor = torch.cat((historical_tensor[:, 3:], final_prediction), dim=1)\n",
    "\n",
    "        # Stack predictions into a single tensor\n",
    "        predictions = torch.cat(predictions, dim=1)  # Shape: [batch_size, forecast_steps]\n",
    "\n",
    "        # Convert pre- and post-attention weights to tensors (optional)\n",
    "        pre_attention_weights = torch.stack(pre_attention_weights, dim=0)  # [steps, batch_size, num_heads, seq_len, seq_len]\n",
    "        post_attention_weights = torch.stack(post_attention_weights, dim=0)  # [steps, batch_size, num_heads, seq_len, seq_len]\n",
    "\n",
    "        # Return predictions, attention weights, and LSTM hidden states\n",
    "        return predictions, pre_attention_weights, post_attention_weights, lstm_hidden_states\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example usage\n",
    "Here is an example of how to use our newly created model:"
   ],
   "id": "ffb934d9de7941ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T11:30:52.829377Z",
     "start_time": "2025-01-10T11:30:52.819137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# Initialize the model - HAVE TO BE ADAPTED TO DATASET (Values are likely correct)\n",
    "def example_usage():\n",
    "    static_feature_dim_num = 4    # Number of static features\n",
    "    historical_dim_num = 12       # Number of historical stock performance points\n",
    "    hidden_dim_num = 128          # Hidden layer size\n",
    "    forecast_steps_num = 12       # Predict next 12 months\n",
    "\n",
    "    batch_size = 2\n",
    "\n",
    "    DATASET_PATH = \"../Dataset/Data/normalized_real_company_stock_dataset_large.csv\"\n",
    "    dataset = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Datasetshape: {dataset.shape}\")\n",
    "\n",
    "    print(f\"Datasetshape: {dataset.shape}\")\n",
    "\n",
    "    retrieval_system = RetrievalSystem(INPUT_PATH, retrieval_number=10)\n",
    "\n",
    "    model = RetrievalAugmentedPredictionModel(\n",
    "        forecast_steps=forecast_steps_num,\n",
    "        ret_sys = retrieval_system,\n",
    "        retrieval_number=10\n",
    "    )\n",
    "\n",
    "    current_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Random entry\n",
    "    idea_entries = dataset.iloc[10:10 + batch_size, :]  # Get a batch of rows\n",
    "\n",
    "    # Removed tickers: Select rows from index 3 onward\n",
    "    removed_tickers = [] # dataset.iloc[100:, :][\"tickers\"].tolist()\n",
    "\n",
    "    # Create excluded_tickers map\n",
    "    excluded_tickers = {\n",
    "        i: [ticker] + removed_tickers  # Include the ticker itself and all removed tickers\n",
    "        for i, ticker in enumerate(dataset[\"tickers\"])\n",
    "    }\n",
    "\n",
    "    ideas = idea_entries[\"business_description\"].tolist()\n",
    "\n",
    "    static_columns = [\n",
    "        col for col in dataset.columns\n",
    "        if col not in [\"tickers\", \"business_description\"] and not col.startswith(\"month\")\n",
    "    ]\n",
    "    month_columns = [col for col in dataset.columns if col.startswith(\"month\")]\n",
    "\n",
    "    # Prepare static and historical data for the batch\n",
    "    static_data = idea_entries[static_columns]\n",
    "    historical_data = idea_entries[month_columns]\n",
    "\n",
    "    # Ensure numeric data and handle missing values\n",
    "    static_data = static_data.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(float)\n",
    "    historical_data = historical_data.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(float)\n",
    "\n",
    "    # Convert to tensors with batch dimension\n",
    "    static_data = torch.tensor(static_data, dtype=torch.float32).to(current_device)  # [batch_size, static_feature_dim_num]\n",
    "    historical_data = torch.tensor(historical_data[:, -2 * forecast_steps_num:-forecast_steps_num], dtype=torch.float32).to(current_device)  # [batch_size, historical_dim_num]\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction, _, _, _ = model(\n",
    "        ideas=ideas,\n",
    "        dataset=dataset,\n",
    "        static_features=static_data,\n",
    "        historical_data=historical_data,\n",
    "        use_auxiliary_inputs=True,\n",
    "        excluded_tickers=excluded_tickers,\n",
    "    )\n",
    "    print(prediction)  # Co\n",
    "    print(prediction.shape)\n",
    "\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction, _, _, _ = model(\n",
    "        ideas=ideas,\n",
    "        dataset=dataset,\n",
    "        use_auxiliary_inputs=False\n",
    "    )\n",
    "    print(prediction)  # Co\n",
    "    print(prediction.shape)\n",
    "\n",
    "\n",
    "\n",
    "    retrieval_result = retrieval_system.find_similar_entries_for_batch(texts=ideas, top_n=5)\n",
    "    prediction, _, _, _ = model(\n",
    "        dataset=dataset,\n",
    "        retrieval_result=retrieval_result,\n",
    "        use_auxiliary_inputs=False,\n",
    "    )\n",
    "\n",
    "    print(prediction)\n",
    "    print(prediction.shape)\n",
    "\n",
    "\n"
   ],
   "id": "43396d2bee8576ad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simple Training Loop",
   "id": "67ab46e00ad78620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T11:30:52.892901Z",
     "start_time": "2025-01-10T11:30:52.875301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, dataset, forecast_steps, static_columns, month_columns):\n",
    "        self.dataset = dataset\n",
    "        self.forecast_steps = forecast_steps\n",
    "        self.static_columns = static_columns\n",
    "        self.month_columns = month_columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idea_entry = self.dataset.iloc[idx]\n",
    "\n",
    "        # Extract idea, static data, historical data, and target\n",
    "        idea = idea_entry[\"business_description\"]\n",
    "        ticker = idea_entry[\"tickers\"]\n",
    "\n",
    "        static_data = idea_entry[self.static_columns]\n",
    "        historical_data = idea_entry[self.month_columns]\n",
    "\n",
    "        # Handle missing values\n",
    "        static_data = static_data.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(float)\n",
    "        historical_data = historical_data.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(float)\n",
    "\n",
    "        # Split target and input\n",
    "        target = torch.tensor(historical_data[-self.forecast_steps:], dtype=torch.float32)\n",
    "        historical_data = torch.tensor(historical_data[:-self.forecast_steps], dtype=torch.float32)\n",
    "\n",
    "        # Return all relevant data\n",
    "        return idea, static_data, historical_data, target, ticker\n",
    "\n",
    "def test_training():\n",
    "    dataset = pd.read_csv(\"../Dataset/normalized_real_company_stock_dataset_large.csv\")\n",
    "    removed_tickers = []\n",
    "    current_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Initialize dataset and DataLoader\n",
    "    static_columns = [\n",
    "        col for col in dataset.columns\n",
    "        if col not in [\"tickers\", \"business_description\"] and not col.startswith(\"month\")\n",
    "    ]\n",
    "    month_columns = [col for col in dataset.columns if col.startswith(\"month\")]\n",
    "\n",
    "    forecast_steps = 6\n",
    "    batch_size = 10\n",
    "    retrieval_number = 10\n",
    "\n",
    "    stock_dataset = StockDataset(dataset, forecast_steps, static_columns, month_columns)\n",
    "    data_loader = DataLoader(stock_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize the model\n",
    "    retrieval_system = RetrievalSystem(INPUT_PATH, retrieval_number=10)\n",
    "    model = RetrievalAugmentedPredictionModel(\n",
    "        forecast_steps=forecast_steps,\n",
    "        ret_sys=retrieval_system,\n",
    "        retrieval_number=10,\n",
    "    )\n",
    "    model.to(current_device)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Initialize storage for loss values\n",
    "    losses = []\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 1\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in data_loader:\n",
    "            ideas, static_data, historical_data, targets, tickers = batch\n",
    "\n",
    "            static_data = static_data.clone().detach().to(current_device)\n",
    "            historical_data = torch.stack([h.clone().detach() for h in historical_data]).to(current_device)\n",
    "            targets = torch.stack([t.clone().detach() for t in targets]).to(current_device)\n",
    "\n",
    "            # Remove tickers in the current batch from the dataset for retrieval\n",
    "            excluded_tickers = list(tickers)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(\n",
    "                ideas=ideas,\n",
    "                dataset=dataset,\n",
    "                static_features=static_data,\n",
    "                historical_data=historical_data,\n",
    "                use_auxiliary_inputs=True,\n",
    "                excluded_tickers={i: [ticker] + removed_tickers for i, ticker in enumerate(excluded_tickers)}\n",
    "            )\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Store epoch loss\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] completed. Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "        return epochs, losses, targets, predictions\n",
    "\n"
   ],
   "id": "3d3559d051a584c6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "46300e763218c4cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T11:30:52.941982Z",
     "start_time": "2025-01-10T11:30:52.937840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot Training Loss\n",
    "def visualize_retrieval_augmented_prediction_model(model, epochs, losses, targets, predictions):\n",
    "    dataset = pd.read_csv(\"../Dataset/normalized_real_company_stock_dataset_large.csv\")\n",
    "    removed_tickers = []\n",
    "    current_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), losses, marker='o', label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Example post-training prediction\n",
    "    example_idea = \"I want to create a coffee shop that uses digital cups to analyze what's in your coffee and its impact on you.\"\n",
    "    prediction = model(\n",
    "        ideas=[example_idea],\n",
    "        dataset=dataset,\n",
    "        use_auxiliary_inputs=False\n",
    "    )\n",
    "    print(\"Prediction after training:\", prediction)\n",
    "\n",
    "    # Plot Predictions vs. Targets\n",
    "    targets_numpy = targets.cpu().detach().numpy()\n",
    "    predictions_numpy = predictions.cpu().detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(predictions_numpy.shape[0]):  # Loop over batch size\n",
    "        plt.plot(targets_numpy[i], label=f\"Target {i+1}\", linestyle='--')\n",
    "        plt.plot(predictions_numpy[i], label=f\"Prediction {i+1}\")\n",
    "    plt.xlabel(\"Forecast Step\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Predictions vs. Targets\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Example post-training prediction\n",
    "    example_idea = \"I want to create a coffee shop that uses digital cups to analyze what's in your coffee and its impact on you.\"\n",
    "    prediction = model(\n",
    "        ideas=[example_idea],\n",
    "        dataset=dataset,\n",
    "        use_auxiliary_inputs=False\n",
    "    )\n",
    "    print(\"Prediction after training:\", prediction)\n"
   ],
   "id": "123c917b2c48f56f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Main\n",
    "Here the test functions can be executed\n"
   ],
   "id": "295789f74add45ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T11:31:09.373301Z",
     "start_time": "2025-01-10T11:30:52.985373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ],
   "id": "a832a8a83ecebc55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasetshape: (7089, 108)\n",
      "Datasetshape: (7089, 108)\n",
      "Embeddings Tensor Shape: torch.Size([10, 384])\n",
      "Similarities Tensor Shape: torch.Size([10])\n",
      "Numeric Tensor Shape: torch.Size([10, 106])\n",
      "Embeddings Tensor Shape: torch.Size([10, 384])\n",
      "Similarities Tensor Shape: torch.Size([10])\n",
      "Numeric Tensor Shape: torch.Size([10, 106])\n",
      "Shape of combined_tensor: torch.Size([2, 10, 256])\n",
      "tensor([[ 0.0041, -0.1347, -0.0604,  0.0047, -0.1349, -0.0614,  0.0057, -0.1348,\n",
      "         -0.0589,  0.0089, -0.1348, -0.0582],\n",
      "        [ 0.0081, -0.1377, -0.0608,  0.0048, -0.1347, -0.0602,  0.0048, -0.1337,\n",
      "         -0.0592,  0.0041, -0.1362, -0.0612]], grad_fn=<CatBackward0>)\n",
      "torch.Size([2, 12])\n",
      "Embeddings Tensor Shape: torch.Size([10, 384])\n",
      "Similarities Tensor Shape: torch.Size([10])\n",
      "Numeric Tensor Shape: torch.Size([10, 106])\n",
      "Embeddings Tensor Shape: torch.Size([10, 384])\n",
      "Similarities Tensor Shape: torch.Size([10])\n",
      "Numeric Tensor Shape: torch.Size([10, 106])\n",
      "Shape of combined_tensor: torch.Size([2, 10, 256])\n",
      "tensor([[ 0.0052, -0.1358, -0.0611,  0.0058, -0.1330, -0.0604,  0.0076, -0.1356,\n",
      "         -0.0597,  0.0069, -0.1356, -0.0598],\n",
      "        [ 0.0061, -0.1341, -0.0589,  0.0059, -0.1359, -0.0607,  0.0060, -0.1352,\n",
      "         -0.0594,  0.0067, -0.1371, -0.0604]], grad_fn=<CatBackward0>)\n",
      "torch.Size([2, 12])\n",
      "Embeddings Tensor Shape: torch.Size([5, 384])\n",
      "Similarities Tensor Shape: torch.Size([5])\n",
      "Numeric Tensor Shape: torch.Size([5, 106])\n",
      "Embeddings Tensor Shape: torch.Size([5, 384])\n",
      "Similarities Tensor Shape: torch.Size([5])\n",
      "Numeric Tensor Shape: torch.Size([5, 106])\n",
      "Shape of combined_tensor: torch.Size([2, 5, 256])\n",
      "tensor([[ 0.0021, -0.1347, -0.0661,  0.0045, -0.1380, -0.0670,  0.0015, -0.1363,\n",
      "         -0.0671,  0.0039, -0.1379, -0.0667],\n",
      "        [ 0.0007, -0.1365, -0.0668,  0.0014, -0.1377, -0.0657,  0.0004, -0.1392,\n",
      "         -0.0673,  0.0009, -0.1373, -0.0666]], grad_fn=<CatBackward0>)\n",
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
